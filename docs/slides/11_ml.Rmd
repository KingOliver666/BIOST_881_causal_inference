---
title: "L11: Machine Learning in Causal Inference"
author: "Jean Morrison"
institute: "University of Michigan"
date: "2022-03-14 (updated: `r Sys.Date()`)"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false


---
# Statistical Models Approximate Distributions

- Statistical models are approximations of joint or conditional probability distributions of observed data. 

- For example, if we have observations $(x_1, y_1), \dots, (x_N, y_N)$ and we fit a simple linear regression of $Y$ on $X$, we are using the model
$$y_i = \beta_0  + \beta_1 x_i + \epsilon_i\\\ \epsilon_i \sim N(0, \sigma_y^2)$$
  + We are approximating the conditional distribution of $Y \vert X$ as normal with mean $\beta_0 + \beta_1X$ and variance $\sigma_y^2$. 
  
- More accurately, the linear model is a *class of models* parametrized by a finite set of parameters (three in our case).

- The OLS procedure identifies the single model within this class that best approximates the distribution of the observed data. 

$\newcommand{\ci}{\perp\!\!\!\perp}$
```{r xaringan-tile-view, echo=FALSE}
xaringanExtra::use_tile_view()
xaringanExtra::use_search(show_icon = TRUE)
xaringanExtra::use_panelset()
```

---
# Machine Learning

- Machine learning methods allow us to expand the class of models in which we look for approximations. 

- ML methods are sometimes described as "learning models automatically" from data. 

- However, all statistical methods are learning models. 

- A unique feature of ML methods, is that the class of models is sometimes allowed to expand as the number of observations increases, allowing increasing complexity. 


---
# Example: Splines

- As an alternative to the linear model, we add parameters to the regression, for example fitting piece-wise functions. 

<center> 
```{r, echo=FALSE, out.width="85%"}
knitr::include_graphics("img/11_spline1.png")
```
</center>

- With fixed knots, these models are only a little more flexible than the linear regression. 

---
# Example: Smoothing Splines

- As an alternative is to approximate the conditional mean of $Y$ given $X$ as a smooth function of $X$. 

$$y_i = h(x_i) + \epsilon_i \qquad h \in \mathcal{H}\\\ \epsilon_i \sim N(0, \sigma_y^2)$$ where $\mathcal{H}$ is a class of "smooth" functions. 

- Smoothness could be definde by a restriction, for example on the second derivative
$$\int (h^{\prime \prime}(x))^2 dx < C$$
  
  
- This class of models does not have a finite parametrization
  - However, it is possible to approximate functions in $\mathcal{H}$ using a finite number of terms. 
  
---
# Example: Smoothing Splines

- We can define a spline basis, an infinite set of functions $g_1(x), g_2(x), \dots$ that allows us to approximate any smooth function well. 
  + Given any smooth $h$ and error tolerance $\varepsilon$, we can find a finite $K$ and a set of coefficients $\beta_1, \dots, \beta_{K}$ such that 

$$\vert h(x) - \sum_{k = 1}^K\beta_k g_k(x) \vert < \varepsilon \ \ \forall x$$


- Using our spline basis, we replace the previous model with
$$y_i = \sum_{k = 1}^{K(N)}\beta_k g_k(x_i) + \epsilon$$  
  + Often $K(N) = N$
  + We then estimate the coefficients $\beta_1, \dots, \beta_K$ via *penalized likelihood. 
  + The penalty controlls the degree of smoothness or the *effective number of parameters*. 
  

---
# Example: Smoothing Splines

<center> 
```{r, echo=FALSE, out.width="85%"}
knitr::include_graphics("img/11_spline2.png")
```
</center>

---
# Bias-Variance Trade-Off

- With no penalization, we could perfectly interpolate the data.

- With an infinite penalty, the problem reduces to simple linear regession. 

- Too little smoothing:
  + The estimate will have a high variance because very little data contributes to the estimate at each point.
  
  
- Too much smoothing: 
  + The estimate has low variance but high bias. 
  
- In practice, we try to learn the amount of smoothing that best fits the data via cross-validation. 

---
# Bias-Variance Trade-Off

<center> 
```{r, echo=FALSE, out.width="62%"}
knitr::include_graphics("img/11_splines.png")
```
</center>

---
# Example: Smoothing Splines

- Smoothing splines allow us to expand the class of models to we use to approximate the conditional distribution of $Y$ given $X$ compared to simple linear regression.

- Allowing the number of spline basis terms to increase as sample size increases provides "built-in" increasing model complexity. 


- When we fit a smoothing spline, we are exploiting having lots of data in order to make weaker assumptions about the relationship between $E[Y \vert X]$ and $X$. . 
  
  
---
# ML Methods are Good at Approximating Data

- There are numerous ML methods which allow us to approximate distributions which much higher complexity than simple regressions. 

- These include 
  + variable selection methods like LASSO. 
  + random forests
  + neural networks
  + empirical Bayes methods (learn the prior from the data)
  
- These are often described as prediction methods but we can also think of them as methods for approximating the distributions of data.


---
# Causal Effects


- Early in this course we defined a causal effect as the average treatment effect
$$E[Y(1)] - E[Y(0)]$$
or possibly the causal risk ratio 
$$\frac{E[Y(1)]}{E[Y(0)]}$$

- The quantity $E[Y(1)]$ is a parameter of the counterfactual distribution of $Y$ under the action setting $A$ to 1. 

- Neither ML methods nor "standard" statistical methods can learn counterfactual distributions. They can only learn distributions of observed data. 

- So we need to express our counterfactual quantity $E[Y(1)]$ in terms of the probability distribution of the observations.


---
# Return to the g-Formula

- To link the probability distribution of the observed data and the counterfactual parameters we are interested in we need a DAG and the g-formula

$$E[Y(a)] = \int E[Y \vert A = a, L = l]dF_l(l)$$

- The DAG is necessary to identify a sufficient set of confounding variables.
  + The data cannot tell us what the correct DAG is. 
  + In some cases it can help. 
  
  
- For this reason, there cannot be any purely automated causal inference. 
  + Job security for statisticians. 

---
# g-Formula Methods

- We saw two ways to use the g-formula. 

- Option 1: Estimate $E[Y \vert A = a, L = l]$
  - Outcome modeling, or plug-in g-formula. 
  - Let $b(a, l) = E[Y \vert A=a, L=l]$
  
- Option 2: Estimate $P[A = a \vert L = l]$
  - Inverse probability weighting or treatment modeling
  - Let $\pi_a(l) = P[A = a \vert L = l]$
  
- Finally, we saw that using double robust methods we can combine the two. 
  - We saw that the bias of DR methods is proportional to $\left(\frac{1}{\hat{\pi}}- \frac{1}{\pi}\right)\left(\hat{b}-b\right)$

---
# Machine Learning in g-Formula Methods

- We can use ML methods to estimate $\pi$ or $b$. 


- **However**, we need to be careful. 

- Neither outcome modeling alone or IP weighting will generally yield an asymptotically normal estimate for general ML methods. 
  + Both methods require that we pre-specify a parametric model with a fixed number of parameters. 


- ML methods are not guaranteed to be consistent. 
  + We may not have included all of the confounders.
  + The set of models the ML method is choosing from may not include the truth. 
  + We may have included variables that induce bias (more on this later).
  
- For this reasons we should use a double robust estimator with ML methods. 
  + Coming up, we will see an especially nice version. 


---
# Asymptotic Linearity

- Let $O_1, \dots, O_n$ be an iid sample from a probability distribution $P$. 

- Let $\hat{\psi}_n$ be an estimator. The subscript $n$ refers to sample size and helps remind us that $\hat{\psi}_n$ is a function of data. 


- $\hat{\psi}_n$ is asymptotically linear if 
$$\hat{\psi}_n = \sum_{i = 1}^n \phi(O_i) + o_p(1)$$
- $\hat{\psi}_n$ looks like an average of some function of each data point. 

- The function $\phi$, is called the influence function, or influence curve. 

- If $\hat{\psi}_n$ is asymptotically linear then $\hat{\psi}_n$ is asymptotically normal. 
  + Result comes from the CLT
  + A highly describable property


---
# Targeted Maximum Likelihood Estimation (TMLE)

- TMLE is a double robust estimation strategy that is very similar to other DR estimators we have seen so far. 

- TMLE yields an asymptotically linear estimator as long as at least one of $\hat{\pi}$ or $\hat{b}$ are consistent. 
  + If both re consistent, the TMLE is also efficient, meaning that it has the smallest possible asymptotic bias of any estimator.
  + These properties are also true of the other DR estimators we have seen.
  
---
# TMLE vs AIPW

- TMLE is guaranteed to yield an estimate of $E[Y(a)]$ that is within the range of the original outcome data. 
  + This is not true of the AIPW estimator (previously the Robins, Rotnitzky, and Zhao estimator)
  
  $$\hat{\Delta}_{DR,1} = \frac{1}{N} \sum_{i = 1}^N \left \lbrace \hat{Y}_{1,i} + \frac{A_i}{\hat{\pi}(L_i)}\left(Y_i - \hat{Y}_{1,i} \right) \right \rbrace$$
- TMLE is also more stable than AIPTW with $\hat{\pi}(L_i)$ are very small for units. 


---
# TMLE Initialization

The following steps produce the TMLE for a binary outcome and binary exposure. 

Step 1: Generate an initial estimate $\hat{b}_0$ of $E[Y \vert A, L]$. 

Step 2: Estimate $\hat{\pi}_a = P[A = a \vert L]$. For binary exposure, we will estimate $\hat{\pi}_1$ and then compute $\hat{\pi}_0 = 1-\hat{\pi}_1$. 

---
# TMLE One-Step Update


Step 3: Update the model of $E[Y \vert A, L]$. To do this we employ the "special covariate" strategy. Define
$$H(A, L) = \frac{I(A = 1)}{\hat{\pi}_1(L)} - \frac{I(A = 0)}{\hat{\pi}_0(L)}$$
Fit the model 

$$logit(E[Y \vert A, L]) = logit(\hat{b}_0(A, L)) + \epsilon H(A,L)$$
Note that the coefficient on the first term is 1, this is an offset. 

We get out an estimate, $\hat{\epsilon}$, called the fluctuation parameter. 

---
# TMLE One-Step Update

Having estimated $\epsilon$, we now have a new outcome estimate,

$$\hat{b}(A, L) = expit\left( logit(\hat{b}_0(A, L)) + \hat{\epsilon}H(A, L)\right)$$

---
# TMLE Final Step

The lest step is to use standardization to estimate $E[Y(a)]$

$$\hat{E}[Y(a)] = \frac{1}{n}\sum_{i=1}^N \hat{b}(a, L_i)$$

---
# TMLE with Continouous Outcome

- With a continuous outcome we can use exactly the same algorithm *except*

- Before we begin, we need to transform $Y$ into the range $[0, 1]$. 

- At the end we need to undo our transformation. 

- Notice that this procedure guarantees us an estimate within the observed range of $Y$. 

---
# Inference

- We can obtain the variance of the treatment effect estimated by TMLE by directly computing the influence function. 

- If $$\hat{\psi}_n = \sum_{i = 1}^n \phi(O_i) + o_p(1)$$ then $\hat{\psi}_n$ is asymptotically normal with mean $E[\phi(O)]$ and variance $\frac{1}{N}Var(\phi(O))$. 

- For TMLE, the influence function for the ATE is

$$\hat{\phi}(O_i) = (Y_i - \hat{b}(A_i, L_i))H(A_i, L_i) + (\hat{b}(1, L_i)- \hat{b}(0, L_i))- \hat{ATE}$$

- We can estimate the variance of the ATE estimate as the sample variance of $\hat{\phi}$ divided by $N$. 

---
# Update Step Intuition

- The update step works because it directly solves a formula for the efficient influence function.

- However, we can have some intuition for why it is necessary without knowing about efficient influence functions. 

- The models we used to estimate $\hat{b}_0$ and $\hat{\pi}$ have made bias-variance trade-offs aimed at optimizing prediction of $Y$ or $A$ respectively. 

- However, predicting $Y$ and $A$ isn't our end goal. Our end goal is estimating the causal effect. 

- The update step adjusts the bias-variance trade-off to improve estimation of the target parameter. 
- This is the source of the "Targeted" in TMLE. 

---
# Super Learner

- We need to decide what estimators to use to get $\hat{b}_0$ and $\hat{\pi}$ in the TMLE algorithm. 

- It may be hard to know which of many possible options will give the best results. 

- In super learning, we use a weighted combination of many learners.
  + The best of all worlds. 
  
- Super learning can improve performance of the TMLE. 

<center> 
```{r, echo=FALSE, out.width="35%"}
knitr::include_graphics("img/11_ring.png")
```
</center>

---
# Super Learner vs TMLE

- The super learner and the TMLE different, seprable methods. 

- Super learner is a machine learning (prediction) method. 

- TMLE is a causal inference method. 

- TMLE can be used with parametric models for $\hat{b}$ and $\hat{\pi}$. 

- Super learner can be used for other prediction problems, including as part of non-TMLE causal estimators.

---
# TMLE with Super Learner

<center> 
```{r, echo=FALSE, out.width="85%"}
knitr::include_graphics("img/11_tmle.png")
```
</center>


---
# TMLE in R

- There are a few R packages which implement TMLE and the super learner. 
  - tmle, tmle3
  - SuperLearner, sl3
  
Tutorials:

[Illustrated Guide to TMLE by Katherine Hoffman](https://www.khstats.com/blog/tmle/tutorial/)

[Estimation Tutorial by Miguel Angel Luque Fernandez](https://migariane.github.io/TMLE.nb.html#1_introduction)

[Targeted Learning in R Handbook](https://tlverse.org/tlverse-handbook/index.html)

---
# TMLE Extensions

Extensions of TMLE have been developed for

- Time-varying exposures, identifying optimal treatment regimes.

- Further improving the update step (collaborative TMLE)

- Mediation analysis



---
# Poisoned Covariates

- The best ML methods in the world cannot save us from a misspecified DAG or from unmeasured confounding. 

- Performance of the TMLE requires that all confounders are measured and included in the model. 

- As we've seen previously, there are some covariates that we should not include in our models, namely
  + Colliders
  + Children of the outcome (sneaky colliders)
  
- We also saw previously that including parents of the exposure that are not on a backdoor path can reduce precision and, if there are unmeasured confounders, increase bias.

---
# Other ML Opportunities

- The TMLE plus Super Learner framework requires that we observe all confounders and get some aspects of the DAG correct.

- Other methods have been proposed for circumstances where there might be unmeasured confounding.

- These methods are fundamentally controversial and reliant on assumptions. 
  + Data fundamentally cannot tell us about what is not in the data. 

- Hopefully one of the ML presentation groups will take us through "the deconfounder" by Wang and Blei and its associated controversy. 



