---
title: "L2: DAGs and Confounding"
author: "Jean Morrison"
institute: "University of Michigan"
date: "2022-01-10 (updated: `r Sys.Date()`)"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---
$\newcommand{\ci}{\perp\!\!\!\perp}$

# Graphical Representations of Casual Effects

+ We can represent causal effects in a graph, with arrows. 

+ Nodes in the graph are random variables. 

+ Directed edges represent direct causal effects (not mediated by any other variables in the graph).

+ The absence of an edge indicates the absence of a direct causal effect. 
--

```{r, echo = FALSE, out.width='90%', fig.height = 2.5, fig.align='left', message = FALSE, warning=FALSE}
library(DiagrammeR)
library(dplyr)
library(knitr)
library(kableExtra)

ay <- create_node_df(n = 5, label = c("A", "Y", "A", "Y", "L"), 
                     fontname = "Helvetica", 
                     fontsize = 10, 
                     width = 0.3, 
                     fillcolor = "white", 
                     fontcolor = "black",
                     color = "black", 
                     x = c(0, 1, 2.2, 3.2, 2.7), 
                     y = c(0, 0, 0, 0, 0.5))
ay_edge <- create_edge_df(from = c(1, 3, 5, 5), to = c(2, 4, 4, 3), 
                          minlen = 1, 
                          color = "black", 
                          )
ay_graph <- create_graph(nodes_df = ay, edges_df = ay_edge)

render_graph(ay_graph)
```

---


# Graph Definitions 

- A graph, $\mathcal{G} = \lbrace V, E\rbrace$ consists of
  - A set of nodes (vertices) $V = \lbrace V_1, \dots, V_J\rbrace$
  - A set of edges $E = \lbrace (V_{1_1}, V_{1_2}), \dots, (V_{K_1}, V_{K_2}) \rbrace$, which can be represented as pairs of nodes.
  
- A graph can be either *directed*, in which case elements of $E$ are ordered pairs or *undirected*, in which case
elements of $E$ are un-ordered. 
  - Our graphs will almost always be directed. 

- Two nodes are *adjacent* if they are connected by an edge. 
  + If the edge is directed, the node at the beginning of the edge is the *parent* and the node at the end is the *child*.

---

# Graph Definitions

- A *path* is a sequence of edges in which each edge contains one node from the previous edge.

- In a directed path, all of the edges are oriented in the same direction: i.e. each edge starts at last node of the previous edge. 

- In this graph:

<center>

```{r, echo = FALSE, out.width='40%', fig.height = 2.5, fig.align='left'}
ayl <- create_node_df(n = 3, label = c("A", "Y", "L"), 
                     fontname = "Helvetica", 
                     fontsize = 10, 
                     width = 0.3, 
                      fillcolor = "white", 
                     color = "black", 
                     x = c(0, 1, 0.5), 
                     y = c(0, 0, 0.5))
ayl_edge <- create_edge_df(from = c( 1, 3, 3), to = c(2, 2, 1), 
                          minlen = 1, 
                          color = "black", 
                          )
ayl_graph <- create_graph(nodes_df = ayl, edges_df = ayl_edge)

render_graph(ayl_graph)
```
</center>

there are two paths from $A$ to $Y$ but only one directed path. 

---

# Graph Definitions

- If there are no paths between two nodes, they are *disconnected* (or *connected* otherwise).

- Node $j$ is a descendant of node $k$ if there is a directed path from $V_j$ to $V_k$. 

- If a graph contains no directed cycles, it is *acyclic*
  + We will require all of our graphs to be acyclic.

- DAG = Directed Acyclic Graph
---

# Example: Different Treatments for Different Patients

+ Consider this story:

  - There are two possible treatments for a disease. Treatment $A$ is more effective than $B$, but has more side effects.
  - Doctors prefer treatment $B$ for patients who are older or who have more mild disease.
  - Patient outcome (remission or not) is affected by initial severity, treatment, and treatment adherence.
  - Conditional on everything else, age has no effect on patient outcome or disease severity.

--

+ Work with your neighbor to arrange the following variables in a DAG:

  - Patient outcome
  - Initial disease severity
  - Treatment
  - Treatment Adherence
  - Age

(The DAG is not uniquely determined from the information given.)

---
# Disease Treatment Example 

<center>
```{r, echo = FALSE, out.width='90%',  fig.align='center'}

di <- create_node_df(n =5, label = c("Age", "Severity", "Treatment", "Outcome", "Adherence"), 
                     fontname = "Helvetica", 
                     fontsize = 12, 
                     fillcolor = "white", 
                     color = "black", 
                     fontcolor = "black",
                     fixedsize = TRUE,
                     width = 1,
                     x = c(0.2, 0.2, 2, 4, 3), 
                     y = c(1.2, -1.2, 0, 0, 1.2))
di_edge <- create_edge_df(from = c(1, 2, 2,3, 5), to = c(3,  3, 4,  4, 4), 
                          minlen = 1, 
                          color = "black", 
                          )
di_graph <- create_graph(nodes_df = di, edges_df = di_edge)

render_graph(di_graph)
```

</center>

---
# Temporality

- Our definition of causality requires that the exposure occur before the outcome in time. 

- Under this restriction, a causal DAG must be consistent with at least one strict ordering of nodes.
  + This requirement rules out the possibility of cycles. 
  
--

- How do we represent a feedback loop?

--
  + We can create multiple nodes representing unique time points (e.g. $A_1, A_2, \dots$), with each node only permitted to have causal effects on future nodes.
  + More on this later. 

<!-- - What if measurements are taken at the same time? -->

<!-- -- -->
<!--   + We are generally forced to assume a temporal ordering even if our observations are taken at the same time.  -->
<!--   + For example, if we measure height and blood pressure, we can assume that height is stable over a long period of time while blood pressure is more variable. -->

---
# Causal Markov Property

- The causal Markov property translates graph structure into probability statements.

+ It states that, conditional on it's parents, each node is independent of all nodes that are not not it's descendants. 

+ This implies that the joint probability distribution of all nodes can be factored as

$$
P(V) = \prod_{j = 1}^{J} P(V_j \vert pa_j).
$$


---

# Example

Conditional independence statements in the disease tratment graph:

$$S\ci A \qquad S\ci Ad \qquad A \ci Ad$$
$$T \ci Ad\ \vert A, S \qquad O \ci A \ \vert S, T, Ad$$
<center>

```{r, echo = FALSE, fig.width = 6, fig.height = 5,  fig.align='center'}
di$label <- c("Age\nA", "Severity\nS", "Treatment\nT", "Outcome\nO", "Adherence\nAd")
di_graph <- create_graph(nodes_df = di, edges_df = di_edge)
render_graph(di_graph)
```

</center>

---

# Example

In our example, we can factor the joint probability as 

$$P(A, S, T, Ad, O) = P(A)P(S)P(Ad)P(T \vert A, S)P(O \vert S, T, Ad)$$

<center>

```{r, echo = FALSE, fig.width = 6, fig.height = 5, fig.align='center'}
render_graph(di_graph)
```

</center>

---

# Exchangeability

- Is the outcome O exchangeable with respect to the treatment? $O(t) \ci T$?

<center>

```{r, echo = FALSE, fig.width = 6, fig.height = 5, fig.align='center'}
render_graph(di_graph)
```

</center>

---

# Recognizing Lack of Exchangeability in a DAG

- Informally, there are two sources of lack of exchangeability:

  + The presence of common causes (confounders) that have not been conditioned on.
  + Common effects (colliders) that have been conditioned on. 
  
- We will see how to formalize these statements and how to use a DAG to identify a sufficient conditioning set to remove confounding.

---

# Common Causes (Confounders)

- The presence of a common cause introduces association between two variables that is not due to a causal effect. 

<center>

```{r, echo = FALSE, fig.width = 6, fig.height = 2.5, fig.align='center'}
#ayl <- ayl %>% mutate( label = recode(label, "A" = "X", "L" = "U"))
ayl_edge0 <- filter(ayl_edge, from != 1)
ayl_graph0 <- create_graph(nodes_df = ayl, edges_df = ayl_edge0)

render_graph(ayl_graph0)
```

</center>

--

- In the disease treatment example, disease severity is a confounder:
  - Sicker patients are more likely to receive drug $B$ and sicker patients are also more likely to have a poor outcome.
  - So there would be an association between treatment and outcome, even if the two drugs worked equally well. 
  
---

# Confounding

- Confounding as a concept is quite old and therefore has been given many definitions. 

- We will define confounding as the lack of exchangeability that results from common causes. 
  
- *Confounders* are variables which can be used to adjust for confounding. 
  + In the graph below, $L_1$ and $L_2$ are both confounders, even though only $L_1$ is a common cause of $A$ and $Y$.
  
<center>

```{r, echo = FALSE, fig.width = 6, fig.height = 2.5, fig.align='center'}

ayll <- create_node_df(n = 4, label = c("A", "Y", "L@_{1}", "L@_{2}"), 
                     fontname = "Helvetica", 
                     fontsize = 10, 
                     width = 0.3, 
                      fillcolor = "white", 
                     color = "black", 
                     x = c(0, 1.5, 0.5, 1), 
                     y = c(0, 0, 0.8, 0.4))
ayll_edge <- create_edge_df(from = c( 3, 3, 4), to = c( 1, 4, 2), 
                          minlen = 1, 
                          color = "black", 
                          )
ayll_graph <- create_graph(nodes_df = ayll, edges_df = ayll_edge)

render_graph(ayll_graph)
```

</center>
---

# Common Effects (Colliders)

+ A variable $L$ is a collider relative to $A$ and $Y$ if $L$ is a descendent of both $A$ and $Y.$ 

+ Conditioning on a collider introduces an association between $A$ and $Y$. 
  - This is not necessarily as intuitive as the bias introduced by a common cause. 
  
<center>

```{r, echo = FALSE, out.width='40%', fig.height = 2.5, fig.align='left'}
ayl_node_collider <- ayl %>% mutate(y = -y)
ayl_edge_collider <- create_edge_df(from = c( 2, 1), to = c(3, 3), 
                          minlen = 1, 
                          color = "black", 
                          )
ayl_graph_collider <- create_graph(nodes_df = ayl_node_collider, edges_df = ayl_edge_collider)

render_graph(ayl_graph_collider)
```


</center>

---

# Collider Example: Routes to Stardom

+ Suppose that in order to become a movie star, one must either be talented or beautiful. 

+ Suppose that in the population, talent and beauty are uncorrelated. 
  - For simplicity, suppose $P(\text{talent}) = P(\text{beauty}) = 0.1$.
  
+ For simplicity, assume that anyone with talent or beauty has the same chance of becoming a star. 

<center>
```{r, echo = FALSE, fig.height = 2.5, fig.align='left'}
ayl_node_collider2 <- ayl_node_collider %>% 
  mutate(label = recode(label, "A" = "Talent", "Y" = "Beauty", "L" = "Stardom"), 
         shape = "ellipse", 
         width = 0.5, fixedsize = FALSE, 
         y = y *1.5)
ayl_graph_collider <- create_graph(nodes_df = ayl_node_collider2, edges_df = ayl_edge_collider)

render_graph(ayl_graph_collider)
```

</center>
---

# Collider Example: Routes to Stardom

+ Tables below show the proportions of talent and beauty in the general population and among stars: 

<center>
```{r, echo = FALSE}
library(knitr)
library(kableExtra)
pop <- data.frame( B_0 = c(0.81, 0.09), B_1 = c(0.09, 0.01) )
stars <- data.frame(B_0 = c(0, round(0.09/0.19, digits = 2)), B_1 = c(round(0.09/0.19, digits = 2), round(0.01/0.19, digits = 2)))
rownames(pop ) <- rownames(stars) <-  c("\\(T = 0\\)", "\\(T = 1\\)")
# full <- cbind(pop, stars)
# knitr::kable(full, row.names = TRUE, col.names =  rep(c("\\(B = 0\\)", "\\(B = 1\\)"), 2), format = 'html')%>%
#    add_header_above(c(" " = 1, "Population" = 2, "Stars" = 2))
 knitr::kable(pop, row.names = TRUE, col.names = c("\\(B = 0\\)", "\\(B = 1\\)"), format = 'html', caption = "Population")%>%
   kable_styling(position = "float_left", full_width = FALSE)
 knitr::kable(stars, row.names = TRUE, col.names = c("\\(B = 0\\)", "\\(B = 1\\)"), format = 'html', caption = "Stars") %>%
  kable_styling(position = "center", full_width = FALSE)
```


</center>

--

- In the population $P[T=1] = P[ T = 1 \vert B = 1] = 0.1$

- Among stars $P[T=1] = 0.1/0.19 = 0.53$, and $P[T = 1 \vert B = 1] = \frac{0.01/0.19}{0.1/0.19} = 0.1$

--

- Among stars, talent and beauty are negatively correlated. Talent is more rare among beautiful stars than among stars as a whole. 
  
- This is because we have conditioned on the collider "Becoming a star". 

---

# Colliders Can Block Confounding

- In the graph below, there is no confounding because there is no common cause of $A$ and $Y$.

- The collider $L_2$ is "blocking" the path from $A$ to $Y$. 

- Causal Markov properties show us that $A$ and $Y$ are independent in this graph. 

- d-Separation formalizes the rules for identifying pairs of independent variables based on graphical rules.


```{r, echo = FALSE, fig.width = 6, fig.height = 2.5, fig.align='center'}
ayll_edge <- create_edge_df(from = c( 3, 3, 2), to = c( 1, 4, 4), 
                          minlen = 1, 
                          color = "black", 
                          )
ayll_graph <- create_graph(nodes_df = ayll, edges_df = ayll_edge)

render_graph(ayll_graph)
```

---

# No Statistical Definition of Confounding

- One commonly given characterization of a confounder is a variable which 

  + Is associated with the exposure.
  + Is associated with the outcome.
  + Is not on the pathway of interest between exposure and outcome. 
  
--

- Note that $L_1$ satisfies all of these criteria but is not a confounder.

<center>

```{r, echo = FALSE, fig.width = 6, fig.height = 2.5, fig.align='center'}

render_graph(ayll_graph)
```

</center>

- Determining confounding requires a causal model. 
  + The data cannot tell you if confounding is present.
  
---

# d-Separation

+ A path is *blocked* if:
  1. Two arrowheads on the path collide ( $\rightarrow W \leftarrow$ ) at a variable that is not being conditioned on *and* which has no descendants in the conditioning set. OR
  1. It contains a non-collider that is being conditioned on. 
  
+ A path is *open* if it is not blocked:
  - It does not contain a collider and no variables on the path are being conditioned on. OR
  - All colliders are conditioned on and no non-colliders are conditioned on.
  
+ Two variables are *d-separated* if all paths between them are blocked. 

---

# d-Separation and the Causal Markov Property

Let $A$, $B$, and $C$ be sets of variables. Verma and Pearl (1988) proved that:

If $A$ and $B$ are d-separated given $C$ then $A \ci B \vert\ C$.

- We will not prove this in class. 

---
# Faithfulness

Faithfulness is the property that, for three sets of variables $A$, $B$, and $C$
$$A \ci B \vert C \Rightarrow\ A \text{ is } d\text{-separated from }B\text{ given }C$$. 

- Violations of faithfulness occur when confounding effects perfectly cancel each other. 
  + Pearl calls these "incidental cancellations". 
  + And then defines "stable" vs "unstable" unbiasedness. Unstable unbiasedness occurs when faithfulness is violated. 
  
- Practically, we can assume that faithfulness is never violated except when it is violated by design.

- Matching studies intentionally violate faithfulness. 

---

# Example

Which pairs of variables are d-Separated? 

<center>
```{r, echo = FALSE, fig.width = 6, fig.height = 5, fig.align='center'}
render_graph(di_graph)
```
</center>

--

- The causal Markov property allowed us to conclude that $T \ci Ad \vert S, A$.
- Because $T$ and $Ad$ are d-separated, we can also conclude that $T \ci Ad$ unconditionally.

---

# Backdoor Path

- A backdoor path from $A$ to $Y$ is a path from $A$ to $Y$ that begins with an edge going *into* $A$. 

<center>

```{r, echo = FALSE, out.width='60%', fig.height = 2.5, fig.align='left', message=FALSE}
ayl2 <- ayl %>% mutate(x = x + 1.5)
ayl2  <- combine_ndfs(ayl, ayl2) #%>% 
        #mutate( label = recode(label, "A" = "X", "L" = "U"))

ayl_edge2 <- create_edge_df(from =3+ c( 1, 3, 1), to = 3+c(2, 2, 3), 
                          minlen = 1, 
                          color = "black", 
                          )
ayl_edge2 <- combine_edfs(ayl_edge, ayl_edge2)
ayl_graph2 <- create_graph(nodes_df = ayl2, edges_df = ayl_edge2)

render_graph(ayl_graph2)
```

```{r, echo = FALSE, out.width='60%', fig.height = 2.5, fig.align='left'}
m_node <- create_node_df(n = 5, label = c("A", "Y", "L", "U@_{1}", "U@_{2}"), 
                     fontname = "Helvetica", 
                     fontsize = 10, 
                     width = 0.3, 
                      fillcolor = "white", 
                     color = "black", 
                     x = c(0, 1.8, 0.9, 0.45, 1.35), 
                     y = c(0, 0, 0.4, 0.9, 0.9))
m_edge <- create_edge_df(from = c(4, 4,5,5, 1, 3), to = c(1,3,3,2, 2, 2), 
                          minlen = 1, 
                          color = "black", 
                          )
m_graph <- create_graph(nodes_df = m_node, edges_df = m_edge)

render_graph(m_graph)
```

</center>


---

# Backdoor Criterion and Exchangeability

Theorem: If a set of variables, $L$, 
  + blocks every backdoor path between $A$ and $Y$ 
  + contains no descendants of $A$,
  
then $Y(a) \ci A \vert L$. 

--
- The two conditions in the theorem are referred to as the *backdoor criterion*. 

--

- To justify this, we need a connection between DAGs and counterfactuals. 

---


# Single World Intervention Graphs (SWIGs)

- SWIGs are a method of including counterfactuals in DAG. 

- To create a SWIG, the node representing the intervened on variable is split into two nodes. 
  - One node represents the natural value of of the variable.
  - The other represents the fixed value due to the intervention.
  


![](img/2_swig1.png)

---

# SWIGs with more than one intervention

<!-- + SWIGs can easily be used to represent intervention on multiple variables. -->

```{r, echo=FALSE, out.width="80%"}
knitr::include_graphics("img/2_swig2.png")
```

<!-- ![](img/2_swig2.png){width=30%} -->

---
# SWIG Procedure

- To represent the counterfactual $Y(a)$, we split the node $A$ in the original graph into two nodes:

- $A$ (in the SWIG) represents the naturally occurring treatment -- what would have occurred with no intervention. 
  + All of the arrows which entered into $A$ in the original DAG will enter into $A$ in the SWIG.
  
- $a$ represents the intervened on value of the treatment. 
  + This variable is fixed at the value $a$ (i.e. it is deterministic rather than random).
  + All arrows which exited $A$ in the original DAG now exit the $a$ intervention node.
  + All variables which were downstream of $A$ in the original DAG are replaced by their counterfactual values. 

---

# Templates

- Each SWIG can represent only a single intervention, i.e. the world in which everyone receives treatment $A = a$. 

- SWIGs cannot represent relationships between counterfactuals "across worlds" (i.e. $Y(0)$ and $Y(1)$ ).

- A template for a particular intervention is the generic version of a SWIG for some hypothetical value of the intervened on variable.
  + A template is graph valued function which takes in a value of the intervened on variable and returns a SWIG.


---

# SWIGs, Exchangeability, and d-Separation

- Conditional exchangeability says that $Y(a) \ci A \vert L$. 

- The SWIG for intervention $A = a$ obeys the causal Markov property. 

- Therefore, if $Y(a)$ and $A$ are d-separated by $L$ in the SWIG, $Y(a)$ and $A$ are conditionally independent given $L$. 

- The backdoor criterion corresponds to the statement that $Y(a)$ and $A$ are $d$-separated by $L$ in the SWIG.

---

# Descendents of $A$ in the Backdoor Criterion

+ Using SWIGs helps show why the backdoor criterion excludes descendants of $A$. 

<center>
```{r, echo=FALSE, out.width="50%"}
knitr::include_graphics("img/2_swig3.png")
```

</center>

+ The SWIG on the right shows that, $Y(x) \ci X \vert L_2(x)$.

+ However, we cannot conclude that $Y(x) \ci X \vert L_2$ because $L_2$ is not on the graph. 

+ If there is a causal effect of $X$ on $Y$, then conditioning on $L_2$ introduces a type of selection bias (more on this in the future).

---

# Examples

<center>

```{r, echo = FALSE, out.width='60%', fig.height = 3, fig.align='left'}
m_edge <- create_edge_df(from = c(4, 4,5,5, 1), to = c(1,3,3,2, 2), 
                          minlen = 1, 
                          color = "black", 
                          )
m_graph <- create_graph(nodes_df = m_node, edges_df = m_edge)

render_graph(m_graph)
```

</center>

--

- $A$ and $Y$ are exchangeable unconditionally. 

- Conditioning on $L$ induces bias. (Pearl calls this M-Bias).

---

# Examples

<center>

```{r, echo = FALSE, out.width='60%', fig.height = 3, fig.align='left'}
m_edge <- create_edge_df(from = c(4, 4,5,5, 1, 3), to = c(1,3,3,2, 2, 2), 
                          minlen = 1, 
                          color = "black", 
                          )
m_graph <- create_graph(nodes_df = m_node, edges_df = m_edge)

render_graph(m_graph)
```

</center>

--

- If $U_1$ and $U_2$ are unobserved, there is no available set of variables we can condition on to remove bias. 

- If we can measure either, $\lbrace U_1, L\rbrace$ and $\lbrace U_2, L \rbrace$ are both sufficient adjustment sets. 


---

# Examples

<center>
```{r, echo = FALSE, out.width='60%', fig.height = 3, fig.align='left'}
f711_node <- create_node_df(n = 4, label = c("A", "Y", "L", "U"), 
                     fontname = "Helvetica", 
                     fontsize = 10, 
                     width = 0.3, 
                      fillcolor = "white", 
                     color = "black", 
                     x = c(0, 1.8, 0.9, 0.45), 
                     y = c(0, 0, 0, 0.5))
f711_edge <- create_edge_df(from = c(1, 3, 4, 4), to = c(3, 2, 1, 3), 
                          minlen = 1, 
                          color = "black", 
                          )
f711_graph <- create_graph(nodes_df = f711_node, edges_df = f711_edge)

render_graph(f711_graph)
```

</center>

-  Conditioning on $U$ blocks all backdoor paths.

- Could we condition on $L$ instead?

--

- No. $L$ is a descendent of $A$, so it does not satisfy the backdoor criterion.
